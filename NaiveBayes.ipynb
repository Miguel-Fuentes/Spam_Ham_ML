{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Naive Bayes "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data Formating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes():\n",
    "    trainList = []\n",
    "    testList = []\n",
    "    classes = {\"spam\", \"ham\"}\n",
    "    os.chdir(\"data\")\n",
    "    for dataset in [\"dataset 1\", \"dataset 2\", \"dataset 3\"]:\n",
    "        os.chdir(dataset)\n",
    "        for folder in [\"train\", \"test\"]:\n",
    "            os.chdir(folder)\n",
    "            for classfication in classes:\n",
    "                os.chdir(classfication)\n",
    "                for file in os.listdir():\n",
    "                    filename = os.fsdecode(file)\n",
    "                    if filename.endswith(\".txt\"):\n",
    "                        with open(filename, encoding='utf8', errors='ignore') as f:\n",
    "                            if folder == \"train\":\n",
    "                                trainList.append((f.read(), classfication))\n",
    "                            elif folder == \"test\":\n",
    "                                testList.append((f.read(), classfication))\n",
    "                os.chdir('..')\n",
    "            os.chdir('..')\n",
    "        print(dataset.capitalize() + \"----------------------\")\n",
    "        print(\"The accuracy for \" + dataset + \" is \" + str(Accuracy(classes, trainList, testList)))\n",
    "        trainList.clear()\n",
    "        testList.clear()\n",
    "        os.chdir('..')\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This function goes through each dataset folder to get the information and store it into two lists (training data list and test list) which will be used as input to our accuracy function which gets the accuracy of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training The Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainMultinomialNB(setClasses, trainingSet):\n",
    "    print(\"Data initialized:\")\n",
    "    print(\"Stared training...\")\n",
    "    V = ExtractVocabulary(trainingSet)\n",
    "    N = CountDocs(trainingSet)\n",
    "    prior ={}\n",
    "    condprob = collections.defaultdict(dict)\n",
    "    TctT = 0\n",
    "    for c in setClasses:\n",
    "        Nc = CountDocsInClass(trainingSet, c)\n",
    "        prior[c] = Nc/N\n",
    "        textC = ConcatenateTextOfAllDocsInClass(trainingSet, c)\n",
    "        for t in V:\n",
    "            Tct = CountTokensofTerm(textC, t)\n",
    "            if TctT == 0:\n",
    "                for tp in V:\n",
    "                    TctT = TctT + CountTokensofTerm(textC, tp) + 1\n",
    "            condprob[t][c] = (Tct + 1)/TctT\n",
    "    return V, prior, condprob"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To use the Naive bayes algorithm we need to find a couple of things from the training data. First we need to find the vocabulary (all the words from instances in the training set), \n",
    "next we need to find the porbailities of instances being a certain class. Lastly we need to find the probability of a word occuring given a class. This function finds all\n",
    "this from the training set and returns those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Applying the Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyMultinomialNB(setClass, Vocab, PriorKnow, Condprobs, testData):\n",
    "    W = ExtractTokensFromDoc(Vocab, testData[0])\n",
    "    score = {}\n",
    "    for c in setClass:\n",
    "        score[c] = math.log(PriorKnow[c])\n",
    "        for t in W:\n",
    "            score[c] += math.log(Condprobs[t][c])\n",
    "    return max(score, key=score.get)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have the information from the training set, we can use it to find the classification of a test data instance. This function finds all the words that are in the instance\n",
    "and takes the sum of the prior probability and the probability of each word in the test instance based on the training data. Once it finds that for each class it chooses the classification\n",
    "with the higher probability and returns that classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finding the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(setClasses, trainingSet, testSet):\n",
    "    #print(\"Initializing trainNB\")\n",
    "    trainNB = TrainMultinomialNB(setClasses, trainingSet)\n",
    "    correctClass = 0\n",
    "    for instance in testSet:\n",
    "        #print(\"Finding classification of testSet\")\n",
    "        if instance[1] == ApplyMultinomialNB(setClasses, trainNB[0], trainNB[1], trainNB[2], instance):\n",
    "            correctClass += 1\n",
    "    #print(\"Found accuracy\")\n",
    "    acc = correctClass/CountDocs(testSet)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So far we are able to find probabilities from the training set and apply them to one instance of the test set. The accuracy function allows us to apply the Naive bayes algorithm\n",
    "to each instance of the test set. It compares the new classification from using Naive Bayes to the one the instance already had, then takes the percent of how many were correctly classified. Using this function in our naive bayes function we can see the accuracies of the different training sets below. This is done by just running the code  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset 1----------------------\n",
    "Data initialized:\n",
    "Stared training...\n",
    "The accuracy for dataset 1 is 0.7280334728033473\n",
    "Dataset 2----------------------\n",
    "Data initialized:\n",
    "Stared training...\n",
    "The accuracy for dataset 2 is 0.6732456140350878\n",
    "Dataset 3----------------------\n",
    "Data initialized:\n",
    "Stared training...\n",
    "The accuracy for dataset 3 is 0.7200736648250461"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
