{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data initialized:\n",
      "Started training...\n",
      "Best Acc:  100.0\n",
      "best Epoch:  20\n",
      "Best lr:  0.01\n",
      "92.46861924686193\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weights = {'w0': 0.5}\n",
    "        self.bias = 0.1\n",
    "        self.trainingSet = {}\n",
    "        self.trainSet70 = {}\n",
    "        self.trainSet30 = {}\n",
    "        self.trainingSetVocab = []\n",
    "        self.testSet = {}\n",
    "        self.classes = [\"ham\", \"spam\"]\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.01\n",
    "        \n",
    "    def bagOfWords(self, text):\n",
    "        return dict(collections.Counter(re.findall(r'\\w+', text)))\n",
    "    \n",
    "    def getData(self, data, directory, trueClass):\n",
    "        for dir_entry in os.listdir(directory):\n",
    "            dir_entry_path = os.path.join(directory, dir_entry)\n",
    "            if os.path.isfile(dir_entry_path):\n",
    "                with open(dir_entry_path,encoding='utf8',errors='ignore') as f:\n",
    "                    text = f.read()\n",
    "                    data.update({dir_entry_path: {'text': text, 'freqWords': bagOfWords(text), 'trueClass': trueClass}})\n",
    "    \n",
    "        \n",
    "    def vocabSet(self, dataSet):\n",
    "        vocab = []\n",
    "        for i in dataSet:\n",
    "            for word in dataSet[i]['freqWords']:\n",
    "                if word not in vocab:\n",
    "                    vocab.append(word)\n",
    "        return vocab\n",
    "\n",
    "    def computeWeights(self, dataSet, weights, lr, epochs):\n",
    "        for i in range(epochs):\n",
    "            for data in dataSet:\n",
    "                sumWeights = weights['w0']\n",
    "                for j in dataSet[data]['freqWords']:\n",
    "                    if j not in weights:\n",
    "                        weights[j] = 0\n",
    "                    sumWeights += weights[j] * dataSet[data]['freqWords'][j]\n",
    "                perceptronOutput = 0\n",
    "                if sumWeights > 0:\n",
    "                    perceptronOutput = 1\n",
    "                targetVal = 0\n",
    "                if dataSet[data]['trueClass'] == 'spam':\n",
    "                    targetVal = 1\n",
    "                for k in dataSet[data]['freqWords']:\n",
    "                    weights[k] += float(lr) * float(targetVal - perceptronOutput) * \\\n",
    "                    float(dataSet[data]['freqWords'][k])\n",
    "    \n",
    "    def classify(self, data, weights):\n",
    "        sumWeights = weights['w0']\n",
    "        for i in data['freqWords']:\n",
    "            if i not in weights:\n",
    "                weights[i] = 0\n",
    "            sumWeights += weights[i] * data['freqWords'][i]\n",
    "        if sumWeights > 0:\n",
    "            return 1 # spam\n",
    "        else:\n",
    "            return 0 # ham\n",
    "    \n",
    "    def preTrain(self):\n",
    "                \n",
    "        lenTrain70= round(len(self.trainingSet.keys()) * 0.7) \n",
    "        lenTrain30 = len(self.trainingSet.keys()) - lenTrain70\n",
    "        \n",
    "        trainingSetKeys = list(self.trainingSet.keys())\n",
    "        train70Keys = trainingSetKeys[-lenTrain70:]\n",
    "        train30Keys = trainingSetKeys[:lenTrain30]\n",
    "\n",
    "        for i in train70Keys:\n",
    "            self.trainSet70[i] = self.trainingSet[i] \n",
    "            \n",
    "        for j in train30Keys:\n",
    "            self.trainSet30[j] = self.trainingSet[j]\n",
    "        \n",
    "        \n",
    "    def train(self, trainSet, lr, epochs):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "          \n",
    "        #self.trainingSetVocab = self.vocabSet(self.trainingSet)\n",
    "        self.trainingSetVocab = self.vocabSet(trainSet)\n",
    "        \n",
    "        for i in self.trainingSetVocab:\n",
    "            self.weights[i] = 0.0\n",
    "        \n",
    "        self.computeWeights(self.trainingSet, self.weights, self.lr, self.epochs)\n",
    "        \n",
    "    def test(self, testSet):\n",
    "        #self.getData(self.testSet, testDir + \"/spam\", \"spam\")\n",
    "        #self.getData(self.testSet, testDir + \"/ham\", \"ham\")\n",
    "        correctGuesses = 0\n",
    "        for i in testSet:\n",
    "            guess = self.classify(testSet[i], self.weights)\n",
    "            if guess == 1:\n",
    "                testSet[i]['learnedClass'] = 'spam'\n",
    "                if testSet[i]['trueClass'] == testSet[i]['learnedClass']:\n",
    "                    correctGuesses += 1\n",
    "            if guess == 0:\n",
    "                testSet[i]['learnedClass'] = 'ham'\n",
    "                if testSet[i]['trueClass'] == testSet[i]['learnedClass']:\n",
    "                    correctGuesses += 1\n",
    "        '''          \n",
    "        print (\"Learning constant: %.4f\" % float(self.lr))\n",
    "        print (\"Number of iterations: %d\" % int(self.epochs))\n",
    "        print (\"Emails classified correctly: %d/%d\" % (correctGuesses, len(testSet)))\n",
    "        print (\"Accuracy: %.4f%%\" % (float(correctGuesses) / float(len(testSet)) * 100.0))\n",
    "        '''\n",
    "        #print (\"Emails classified correctly: %d/%d\" % (correctGuesses, len(testSet)))\n",
    "        return (float(correctGuesses) / float(len(testSet)) * 100.0)\n",
    "\n",
    "        \n",
    "def main(trainDir, testDir):\n",
    "    lrs = [0.01, 0.03, 0.05, 0.1, 0.15]\n",
    "    epochs = [5, 10, 20, 50, 100]\n",
    "    maxAccuracy = 0\n",
    "    bestEpoch = 0\n",
    "    bestLr = 0\n",
    "    \n",
    "    perceptron = Perceptron()\n",
    "    perceptron.getData(perceptron.trainingSet, trainDir + \"/spam\", \"spam\")\n",
    "    perceptron.getData(perceptron.trainingSet, trainDir + \"/ham\", \"ham\")\n",
    "    perceptron.getData(perceptron.testSet, testDir + \"/spam\", \"spam\")\n",
    "    perceptron.getData(perceptron.testSet, testDir + \"/ham\", \"ham\")\n",
    "    \n",
    "    print(\"Data initialized:\")\n",
    "    print(\"Started training...\")\n",
    "    \n",
    "    perceptron.preTrain()\n",
    "    for i in range(len(epochs)):\n",
    "        for j in range(len(lrs)):\n",
    "            perceptron.train(perceptron.trainSet70, lrs[i], epochs[j])\n",
    "            acc = perceptron.test(perceptron.trainSet30)\n",
    "            if acc > maxAccuracy:\n",
    "                maxAccuracy = acc\n",
    "                bestEpoch = epochs[j]\n",
    "                bestLr = lrs[i]\n",
    "                \n",
    "    print('Best Acc: ', maxAccuracy)\n",
    "    print('best Epoch: ', bestEpoch)\n",
    "    print('Best lr: ', bestLr)\n",
    "    \n",
    "    perceptron.train(perceptron.trainingSet, bestLr, bestEpoch*5)\n",
    "    acc = perceptron.test(perceptron.testSet)\n",
    "    print(acc)\n",
    "    \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main('data/dataset 1/train', 'data/dataset 1/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
