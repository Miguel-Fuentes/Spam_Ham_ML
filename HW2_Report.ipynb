{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Group Part Report\n",
    "Team: Miguel Fuentes, Dan Cortes, Vineeth Gutta, Praveena Adavikolanu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # this library is used for the dataframe data structure\n",
    "\n",
    "train1 = pd.read_pickle('data\\\\dataset 1\\\\train.pkl')\n",
    "test1 = pd.read_pickle('data\\\\dataset 1\\\\test.pkl')\n",
    "\n",
    "train2 = pd.read_pickle('data\\\\dataset 2\\\\train.pkl')\n",
    "test2 = pd.read_pickle('data\\\\dataset 2\\\\test.pkl')\n",
    "\n",
    "train3 = pd.read_pickle('data\\\\dataset 3\\\\train.pkl')\n",
    "test3 = pd.read_pickle('data\\\\dataset 3\\\\test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on data set 1: 0.9602510460251046\n",
      "Accuracy on data set 2: 0.956140350877193\n",
      "Accuracy on data set 3: 0.9300184162062615\n"
     ]
    }
   ],
   "source": [
    "import naive_bayes # this holds our implementation of naive bayes\n",
    "\n",
    "model1 = naive_bayes.NaiveBayes()\n",
    "model1.train(train1, ['spam', 'ham'])\n",
    "print(f'Accuracy on data set 1: {naive_bayes.accuracy(model1, test1)}')\n",
    "\n",
    "model2 = naive_bayes.NaiveBayes()\n",
    "model2.train(train2, ['spam', 'ham'])\n",
    "print(f'Accuracy on data set 2: {naive_bayes.accuracy(model2, test2)}')\n",
    "\n",
    "model3 = naive_bayes.NaiveBayes()\n",
    "model3.train(train1, ['spam', 'ham'])\n",
    "print(f'Accuracy on data set 3: {naive_bayes.accuracy(model3, test3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import and Formatting\n",
    "The following block of code is used to process the data into the form which is appropriate for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import spam_ham_util # this holds a data formatting utility\n",
    "\n",
    "DataSet = namedtuple('DataSet',['X_train', 'X_test', 'Y_train', 'Y_test'])\n",
    "\n",
    "dataset1 = DataSet(*spam_ham_util.df_to_numeric(train1, test1))\n",
    "dataset2 = DataSet(*spam_ham_util.df_to_numeric(train2, test2))\n",
    "dataset3 = DataSet(*spam_ham_util.df_to_numeric(train3, test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamater Tuning\n",
    "In the following block we test various values for the regulerization constant and see which one results in the best accuracy on a 70/30 split of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with l2_reg = 0 is: 0.9226321634204023\n",
      "Average accuracy with l2_reg = 0.15 is: 0.9351634220573851\n",
      "Average accuracy with l2_reg = 0.3 is: 0.9397029512345955\n",
      "Average accuracy with l2_reg = 0.45 is: 0.9392331545391706\n",
      "Average accuracy with l2_reg = 0.6 is: 0.9321099642025509\n",
      "Average accuracy with l2_reg = 0.75 is: 0.8805858005107301\n"
     ]
    }
   ],
   "source": [
    "# This accuracy calculator was not written by us\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import log_regression # this holds our implementation of logistic regression\n",
    "\n",
    "ITERS, LEARNING_RATE = 100000, 0.01\n",
    "best_reg_val = None\n",
    "best_acc = 0\n",
    "\n",
    "for l2_reg in [0, 0.15, 0.3, 0.45, 0.6, 0.75]:\n",
    "    accs = []\n",
    "    for dataset in [dataset1, dataset2, dataset3]:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(dataset.X_train, dataset.Y_train, test_size=0.30, random_state=17)\n",
    "        \n",
    "        model = log_regression.log_regression(ITERS, l2_reg, LEARNING_RATE)\n",
    "        model.train(X_train, Y_train)\n",
    "        \n",
    "        accs.append(accuracy_score(model.predict(X_test), Y_test))\n",
    "    acc = sum(accs)/len(accs)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_reg_val = l2_reg\n",
    "    print(f'Average accuracy with l2_reg = {l2_reg} is: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Accuracy\n",
    "Now that the regularization constant has been chosen we will train on the entire training set and report accuracy on each of the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Using l2_reg = 0.3 -------------------------------\n",
      "Accuracy of dataset1 is : 0.9079497907949791\n",
      "Accuracy of dataset2 is : 0.9035087719298246\n",
      "Accuracy of dataset3 is : 0.9539594843462247\n"
     ]
    }
   ],
   "source": [
    "print(f'----------------- Using l2_reg = {best_reg_val} -------------------------------')\n",
    "\n",
    "for index, dataset in enumerate([dataset1, dataset2, dataset3]):\n",
    "    model = log_regression.log_regression(ITERS, best_reg_val, LEARNING_RATE)\n",
    "    model.train(dataset.X_train, dataset.Y_train)\n",
    "    \n",
    "    print(f'Accuracy of dataset{index + 1} is : {accuracy_score(model.predict(dataset.X_test), dataset.Y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Algorithm\n",
    "This code will report the optimal hyperparamaters and the accuracy when trained on all the training data for every dataset individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET 1---------------------------------\n",
      "\n",
      "Data initialized:\n",
      "Started training...\n",
      "\n",
      "Best results from hyperparameter tuning:\n",
      "Best Acc:  100.0\n",
      "best Epoch:  75\n",
      "Best lr:  0.01\n",
      "\n",
      "RESULTS FROM ENTIRE DATASET:\n",
      "\n",
      "Learning rate: 0.0100\n",
      "Number of epochs: 75\n",
      "Emails classified correctly: 443/478\n",
      "Accuracy: 92.6778%\n",
      "\n",
      "DATASET 2---------------------------------\n",
      "\n",
      "Data initialized:\n",
      "Started training...\n",
      "\n",
      "Best results from hyperparameter tuning:\n",
      "Best Acc:  100.0\n",
      "best Epoch:  75\n",
      "Best lr:  0.01\n",
      "\n",
      "RESULTS FROM ENTIRE DATASET:\n",
      "\n",
      "Learning rate: 0.0100\n",
      "Number of epochs: 75\n",
      "Emails classified correctly: 414/456\n",
      "Accuracy: 90.7895%\n",
      "\n",
      "DATASET 3---------------------------------\n",
      "\n",
      "Data initialized:\n",
      "Started training...\n",
      "\n",
      "Best results from hyperparameter tuning:\n",
      "Best Acc:  100.0\n",
      "best Epoch:  75\n",
      "Best lr:  0.01\n",
      "\n",
      "RESULTS FROM ENTIRE DATASET:\n",
      "\n",
      "Learning rate: 0.0100\n",
      "Number of epochs: 75\n",
      "Emails classified correctly: 501/543\n",
      "Accuracy: 92.2652%\n"
     ]
    }
   ],
   "source": [
    "import perceptron # this is our implementation of the perceptron algorithm\n",
    "\n",
    "print(\"DATASET 1---------------------------------\")\n",
    "perceptron.main('data\\\\dataset 1\\\\train', 'data\\\\dataset 1\\\\test')\n",
    "print(\"\\nDATASET 2---------------------------------\")\n",
    "perceptron.main('data\\\\dataset 2\\\\train', 'data\\\\dataset 2\\\\test')\n",
    "print(\"\\nDATASET 3---------------------------------\")\n",
    "perceptron.main('data\\\\dataset 3\\\\train', 'data\\\\dataset 3\\\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
