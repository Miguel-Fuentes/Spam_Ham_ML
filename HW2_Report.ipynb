{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Group Part Report\n",
    "Team: Miguel Fuentes, Dan Cortes, Vineeth Gutta, Praveena Adavikolanu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # this library is used for the dataframe data structure\n",
    "\n",
    "train1 = pd.read_pickle('data\\\\dataset 1\\\\train.pkl')\n",
    "test1 = pd.read_pickle('data\\\\dataset 1\\\\test.pkl')\n",
    "\n",
    "train2 = pd.read_pickle('data\\\\dataset 2\\\\train.pkl')\n",
    "test2 = pd.read_pickle('data\\\\dataset 2\\\\test.pkl')\n",
    "\n",
    "train3 = pd.read_pickle('data\\\\dataset 3\\\\train.pkl')\n",
    "test3 = pd.read_pickle('data\\\\dataset 3\\\\test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on data set 1: 0.9602510460251046\n",
      "Accuracy on data set 2: 0.956140350877193\n",
      "Accuracy on data set 3: 0.9300184162062615\n"
     ]
    }
   ],
   "source": [
    "import NaiveBayes # this holds our implementation of naive bayes\n",
    "\n",
    "model1 = NaiveBayes.NaiveBayes()\n",
    "model1.train(train1, ['spam', 'ham'])\n",
    "print(f'Accuracy on data set 1: {NaiveBayes.accuracy(model1, test1)}')\n",
    "\n",
    "model2 = NaiveBayes.NaiveBayes()\n",
    "model2.train(train2, ['spam', 'ham'])\n",
    "print(f'Accuracy on data set 2: {NaiveBayes.accuracy(model2, test2)}')\n",
    "\n",
    "model3 = NaiveBayes.NaiveBayes()\n",
    "model3.train(train1, ['spam', 'ham'])\n",
    "print(f'Accuracy on data set 3: {NaiveBayes.accuracy(model3, test3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import and Formatting\n",
    "The following block of code is used to process the data into the form which is appropriate for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import spam_ham_util # this holds a data formatting utility\n",
    "\n",
    "DataSet = namedtuple('DataSet',['X_train', 'X_test', 'Y_train', 'Y_test'])\n",
    "\n",
    "dataset1 = DataSet(*spam_ham_util.df_to_numeric(train1, test1))\n",
    "dataset2 = DataSet(*spam_ham_util.df_to_numeric(train2, test2))\n",
    "dataset3 = DataSet(*spam_ham_util.df_to_numeric(train3, test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamater Tuning\n",
    "In the following block we test various values for the regulerization constant and see which one results in the best accuracy on a 70/30 split of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy with l2_reg = 0 is: 0.9254289873829026\n",
      "Average accuracy with l2_reg = 0.15 is: 0.9351634220573851\n",
      "Average accuracy with l2_reg = 0.3 is: 0.9334917711103717\n",
      "Average accuracy with l2_reg = 0.45 is: 0.9434449955563501\n",
      "Average accuracy with l2_reg = 0.6 is: 0.9420299785016707\n",
      "Average accuracy with l2_reg = 0.75 is: 0.9365073848443676\n"
     ]
    }
   ],
   "source": [
    "# This accuracy calculator was not written by us\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import log_regression # this holds our implementation of logistic regression\n",
    "\n",
    "ITERS, LEARNING_RATE = 100000, 0.01\n",
    "\n",
    "for l2_reg in [0, 0.15, 0.3, 0.45, 0.6, 0.75]:\n",
    "    accs = []\n",
    "    for dataset in [dataset1, dataset2, dataset3]:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(dataset.X_train, dataset.Y_train, test_size=0.30, random_state=17)\n",
    "        \n",
    "        model = log_regression.log_regression(ITERS, l2_reg, LEARNING_RATE)\n",
    "        model.train(X_train, Y_train)\n",
    "        \n",
    "        accs.append(accuracy_score(model.predict(X_test), Y_test))\n",
    "    print(f'Average accuracy with l2_reg = {l2_reg} is: {sum(accs)/len(accs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Accuracy\n",
    "Now that the regularization constant has been chosen to be 0.45 we will train on the entire training set and report accuracy on each of the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of dataset1 is : 0.9058577405857741\n",
      "Accuracy of dataset2 is : 0.9057017543859649\n",
      "Accuracy of dataset3 is : 0.9631675874769797\n"
     ]
    }
   ],
   "source": [
    "best_reg_val = 0.45\n",
    "\n",
    "for index, dataset in enumerate([dataset1, dataset2, dataset3]):\n",
    "    model = log_regression.log_regression(ITERS, best_reg_val, LEARNING_RATE)\n",
    "    model.train(dataset.X_train, dataset.Y_train)\n",
    "    \n",
    "    print(f'Accuracy of dataset{index + 1} is : {accuracy_score(model.predict(dataset.X_test), dataset.Y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Algorithm\n",
    "This code will report the optimal hyperparamaters and the accuracy when trained on all the training data for every dataset individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET 1---------------------------------\n",
      "\n",
      "Data initialized:\n",
      "Started training...\n",
      "\n",
      "Best results from hyperparameter tuning:\n",
      "Best Acc:  100.0\n",
      "best Epoch:  75\n",
      "Best lr:  0.01\n",
      "\n",
      "RESULTS FROM ENTIRE DATASET:\n",
      "\n",
      "Learning rate: 0.0100\n",
      "Number of epochs: 75\n",
      "Emails classified correctly: 443/478\n",
      "Accuracy: 92.6778%\n",
      "\n",
      "DATASET 2---------------------------------\n",
      "\n",
      "Data initialized:\n",
      "Started training...\n",
      "\n",
      "Best results from hyperparameter tuning:\n",
      "Best Acc:  100.0\n",
      "best Epoch:  75\n",
      "Best lr:  0.01\n",
      "\n",
      "RESULTS FROM ENTIRE DATASET:\n",
      "\n",
      "Learning rate: 0.0100\n",
      "Number of epochs: 75\n",
      "Emails classified correctly: 414/456\n",
      "Accuracy: 90.7895%\n",
      "\n",
      "DATASET 3---------------------------------\n",
      "\n",
      "Data initialized:\n",
      "Started training...\n",
      "\n",
      "Best results from hyperparameter tuning:\n",
      "Best Acc:  100.0\n",
      "best Epoch:  75\n",
      "Best lr:  0.01\n",
      "\n",
      "RESULTS FROM ENTIRE DATASET:\n",
      "\n",
      "Learning rate: 0.0100\n",
      "Number of epochs: 75\n",
      "Emails classified correctly: 501/543\n",
      "Accuracy: 92.2652%\n"
     ]
    }
   ],
   "source": [
    "import perceptron # this is our implementation of the perceptron algorithm\n",
    "\n",
    "print(\"DATASET 1---------------------------------\")\n",
    "perceptron.main('data\\\\dataset 1\\\\train', 'data\\\\dataset 1\\\\test')\n",
    "print(\"\\nDATASET 2---------------------------------\")\n",
    "perceptron.main('data\\\\dataset 2\\\\train', 'data\\\\dataset 2\\\\test')\n",
    "print(\"\\nDATASET 3---------------------------------\")\n",
    "perceptron.main('data\\\\dataset 3\\\\train', 'data\\\\dataset 3\\\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
